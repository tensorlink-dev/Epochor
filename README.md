<div align="center">
    <img src="docs/assets/epochor_logo.png#gh-dark-mode-only" width="300px">
    <img src="docs/assets/epochor_logo.png#gh-light-mode-only" width="300px">
</div>

# Epochor Subnet | SN13

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Our Mission
Our mission is to incentivize and democratize temporal intelligence. We are building an open-source, decentralized platform for time-series models that empowers anyone, anywhere, to develop and share state-of-the-art predictive models. By fostering collective innovation, we aim to ensure transparent, reproducible, and incentive-aligned progress towards robust, generalist temporal reasoning for the economic benefit of all.

---

## ğŸ“œ Overview

Epochor is a Bittensor subnet that **incentivizes the creation of foundational time-series models**. Validators now **own the entire training loop**: they choose the datasets, number of steps, hardware, and evaluation routine. Miners provide lightweight Python submissions that implement a small contract (model construction, optimizer selection, and the per-batch training step). Validators load those submissions, train the models inside a sandboxed loop, and score the resulting checkpoints on synthetic and real-world datasets (currently with **CRPS**).

Competitions rotate dynamically, and **the top-performing miner in each competition earns the largest share of rewards**, while other miners still receive proportionally smaller allocations. This **winner-makes-most** structure creates strong incentives for innovation while maintaining fairness across participants.

The repository builds upon the work of the [Pretrain Subnet](https://github.com/opentensor/pretrain) while retooling the validator workflow around submission-driven training.

---

## Subnet Flow

```
 Miner submission (miner_submission.py)
        â”‚
        â–¼
 Remote submission store (e.g. private HF repo)
        â”‚
        â–¼
 Validator (neurons/validator.py)
        â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Services â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ ModelManager      â†’ sync miner submissions    â”‚
 â”‚ Training Loop     â†’ run validator-owned steps â”‚
 â”‚ EvaluationService â†’ score trained checkpoints â”‚
 â”‚ ScoringService    â†’ compute CRPS + weights    â”‚
 â”‚ State/EMA         â†’ smooth scores             â”‚
 â”‚ WeightSetter      â†’ submit set_weights        â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
 Subtensor (on-chain weights & rewards)
        â”‚
        â–¼
 Rewards distributed via validator-managed scoring
```

---

## âœ¨ Key Features & Design Principles

Epochor's design incorporates several key features to ensure a fair, competitive, and exploitation-resistant environment.

### ğŸ† Winner-Makes-Most Incentives
Rewards are weighted so the **#1 ranked miner receives the majority of emissions** for each competition. Other miners receive smaller proportional shares. This ensures competitiveness while still rewarding participation.

### ğŸ›¡ï¸ Sybil Resistance
The winner-makes-most mechanism makes Sybil attacks unprofitable. Running many mediocre nodes yields minimal returns â€” miners must focus resources into building genuinely competitive models.

### ğŸ’¡ Innovation Over Imitation
Validator-run safeguards discourage duplicate or plagiarized models. Challengers must demonstrate **clear improvement in the scoring metric** to overtake the leader, forcing true innovation.

### ğŸ§  Zero-Shot Generalization
Validators draw from a **broad and rotating set of datasets** (synthetic + real). Miners never know which competition comes next, ensuring that rewarded models are **generalist** rather than overfit.

### âš™ï¸ Standardized Interface
Miners target a compact API: subclasses of `epochor.model.base.BaseTemporalModel` plus the `MinerSubmissionProtocol` hooks (`build_model`, `build_optimizer`, `train_step`). Validators run those hooks inside an audited training harness, guaranteeing apples-to-apples comparisons regardless of the underlying architecture.

---

## âš™ï¸ Scoring Mechanism

All competitions use a **consistent scoring pipeline**, with the **current primary metric being CRPS** (Continuous Ranked Probability Score). Future competitions may introduce additional or alternative metrics as needed.

1. **Data Generation** â€“ Fresh datasets (synthetic GP kernels, financial returns, etc.) are created or loaded each round.  
2. **Forecasting** â€“ Validators fetch miner models from Hugging Face and run them on unseen data.  
3. **Evaluation** â€“ Forecasts are scored using **CRPS** (ensemble CRPS when probabilistic sampling is available).  
4. **Smoothing** â€“ Scores are tracked with an **Exponential Moving Average (EMA)** for stability.  
5. **Clone Assessment** â€“ Duplicate detection prevents trivial copies from gaming rewards.  
6. **Reward Allocation** â€“ The **winner receives the majority share**, others get smaller proportional weights.  

---

## ğŸ“‚ Project Structure

```
epochor/
 â”œâ”€ datasets/       # dataset loaders & IDs
 â”œâ”€ evaluation/     # CRPS scoring pipeline
 â”œâ”€ generators/     # synthetic time-series generators
 â”œâ”€ model/          # submission tracker, stores, constraints
 â”œâ”€ training/       # validator-run training harness & contract
 â”œâ”€ validation/     # EMA tracker & stats helpers
 â”œâ”€ utils/          # logging, hashing, misc helpers
neurons/validator/
 â”œâ”€ competition_manager.py  # schedules datasets
 â”œâ”€ evaluation_service.py   # trains + evaluates submissions
 â”œâ”€ model_manager.py        # syncs miner submissions
 â”œâ”€ scoring_service.py      # turns metrics into weights
 â”œâ”€ state.py                # persisted validator state
 â”œâ”€ weight_setter.py        # submits weights on-chain
 â””â”€ validator.py            # orchestrates the validator
```

---

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/tensorlink-dev/epochor-subnet.git
   cd epochor-subnet
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment**
   ```bash
   cp .env.example .env
   # Add your WANDB_API_KEY and HF_TOKEN
   ```

4. **Run a neuron**
   - Validator:
     ```bash
     python examples/run_validator.py \
       --wallet.name <validator_wallet> \
       --wallet.hotkey <validator_hotkey> \
       --subtensor.network <network_name> \
       --netuid <epochor_netuid>
     ```
   - Miner:
     1. Implement `miner_submission.py` exposing `get_submission()` with the `MinerSubmissionProtocol` hooks.
     2. Package and upload the submission to your configured remote store (e.g. a private Hugging Face repo).
     3. Run the lightweight heartbeat miner (see `neurons/miner.py`) to stay registered on the subnet.

---

## ğŸ›¡ï¸ Safety and Best Practices
- **Secure Your Keys** â€“ Never commit wallet keys.  
- **Resource Management** â€“ Monitor GPU/CPU usage.  
- **Testing** â€“ Validate in testnet before mainnet deployment.  
- **Stay Updated** â€“ Sync with latest Bittensor + Epochor changes.  
- **Monitor Logs** â€“ Track metrics in WandB and logs.  

---
